import { ApiService } from './ApiService';
import { getTtsService } from './TtsService';

// Video generation quality presets
export enum VideoQuality {
  DRAFT = 'draft',       // Fastest, lowest quality
  STANDARD = 'standard', // Balanced speed/quality
  HIGH = 'high',         // High quality, slower
  ULTRA = 'ultra'        // Maximum quality, slowest
}

// Video generation options
export interface VideoGenerationOptions {
  quality: VideoQuality;
  fps: number;
  width: number;
  height: number;
  duration: number;
  useTts: boolean;
  ttsVoice?: string;
  useUpscaling: boolean;
  useMotionGuidance: boolean;
  useControlNet: boolean;
  controlNetType?: string;
  useLoRA?: boolean;
  loraModel?: string;
  loraStrength?: number;
  useTurbo?: boolean;
}

// Default video generation options
export const DEFAULT_VIDEO_OPTIONS: VideoGenerationOptions = {
  quality: VideoQuality.STANDARD,
  fps: 24,
  width: 512,
  height: 512,
  duration: 5,
  useTts: true,
  useUpscaling: true,
  useMotionGuidance: true,
  useControlNet: false,
  useTurbo: true,
};

// Video generation progress
export interface GenerationProgress {
  status: 'preparing' | 'generating_script' | 'generating_audio' | 'generating_frames' | 'compositing' | 'complete' | 'error';
  message: string;
  progress: number; // 0-100
  currentStep: number;
  totalSteps: number;
  error?: string;
}

// Video generation result
export interface GenerationResult {
  videoUrl?: string;
  audioUrl?: string;
  script?: string;
  promptId?: string;
  error?: string;
}

// Main video generation service
export class VideoGenerationService {
  private api: ApiService;
  private options: VideoGenerationOptions;
  private isCancelled: boolean = false;
  private progressCallback?: (progress: GenerationProgress) => void;

  constructor(api: ApiService, options?: Partial<VideoGenerationOptions>) {
    this.api = api;
    this.options = { ...DEFAULT_VIDEO_OPTIONS, ...(options || {}) };
  }

  // Update video generation options
  public setOptions(options: Partial<VideoGenerationOptions>): void {
    this.options = { ...this.options, ...options };
  }

  // Get current options
  public getOptions(): VideoGenerationOptions {
    return { ...this.options };
  }

  // Cancel ongoing generation
  public cancel(): void {
    this.isCancelled = true;
    // Try to interrupt the ComfyUI execution
    this.api.interruptExecution().catch(error => {
      console.error('Failed to interrupt execution:', error);
    });
  }

  // Reset cancel flag
  private resetCancel(): void {
    this.isCancelled = false;
  }

  // Update progress
  private updateProgress(
    status: GenerationProgress['status'],
    message: string,
    progress: number,
    currentStep: number,
    totalSteps: number,
    error?: string
  ): void {
    if (this.progressCallback) {
      this.progressCallback({
        status,
        message,
        progress,
        currentStep,
        totalSteps,
        error
      });
    }
  }

  // Generate a script from a prompt using AI
  private async generateScript(prompt: string): Promise<string> {
    // This is a placeholder. In a real implementation, this would call an AI service
    // like OpenAI's GPT or Google's Gemini to generate a script
    
    // For now, we'll just return the prompt as the script
    return `Script based on: "${prompt}"\n\nThis is a placeholder script that would normally be generated by an AI service like GPT or Gemini. The script would be structured with an introduction, body, and conclusion, optimized for the requested video duration.`;
  }

  // Create an optimized workflow for video generation based on options
  private createVideoWorkflow(
    prompt: string, 
    negativePrompt: string = "blurry, bad quality, worst quality, low resolution", 
    options?: Partial<VideoGenerationOptions>
  ): any {
    const mergedOptions = { ...this.options, ...(options || {}) };
    
    // Base workflow structure depends on quality setting
    let workflow: any;
    
    if (mergedOptions.useTurbo) {
      // Use SDXL Turbo for ultra-fast generation
      workflow = this.createTurboWorkflow(prompt, negativePrompt, mergedOptions);
    } else if (mergedOptions.quality === VideoQuality.DRAFT) {
      // Draft quality - fastest generation
      workflow = this.createDraftWorkflow(prompt, negativePrompt, mergedOptions);
    } else if (mergedOptions.quality === VideoQuality.HIGH || mergedOptions.quality === VideoQuality.ULTRA) {
      // High quality - slower but better results
      workflow = this.createHighQualityWorkflow(prompt, negativePrompt, mergedOptions);
    } else {
      // Standard quality - balanced approach
      workflow = this.createStandardWorkflow(prompt, negativePrompt, mergedOptions);
    }
    
    return workflow;
  }
  
  // Create a turbo-optimized workflow (fastest)
  private createTurboWorkflow(prompt: string, negativePrompt: string, options: VideoGenerationOptions): any {
    // This is a simplified example - in reality, this would be a much more complex workflow
    return {
      "prompt": {
        "1": {
          "inputs": {
            "seed": Math.floor(Math.random() * 1000000),
            "steps": options.quality === VideoQuality.DRAFT ? 1 : 
                    options.quality === VideoQuality.STANDARD ? 2 : 
                    options.quality === VideoQuality.HIGH ? 4 : 6,
            "cfg": 1.5,
            "sampler_name": "euler",
            "scheduler": "karras",
            "denoise": 1,
            "model": "sd_xl_turbo_1.0_fp16.safetensors",
            "positive": prompt,
            "negative": negativePrompt,
            "latent_image": ["2", 0]
          },
          "class_type": "KSampler"
        },
        "2": {
          "inputs": {
            "width": options.width,
            "height": options.height,
            "batch_size": options.fps * options.duration
          },
          "class_type": "EmptyLatentImage"
        },
        "3": {
          "inputs": {
            "samples": ["1", 0],
            "vae": "sdxl_vae.safetensors"
          },
          "class_type": "VAEDecode"
        },
        "4": {
          "inputs": {
            "images": ["3", 0],
            "frame_rate": options.fps,
            "loop_count": 0,
            "filename_prefix": "turbo_video",
            "format": "mp4",
            "crf": 20,
            "save_metadata": true
          },
          "class_type": "SaveVideo"
        }
      }
    };
  }
  
  // Create a draft quality workflow (very fast)
  private createDraftWorkflow(prompt: string, negativePrompt: string, options: VideoGenerationOptions): any {
    return {
      "prompt": {
        "1": {
          "inputs": {
            "seed": Math.floor(Math.random() * 1000000),
            "steps": 10,
            "cfg": 5,
            "sampler_name": "euler_a",
            "scheduler": "karras",
            "denoise": 1,
            "model": "sd_xl_base_1.0.safetensors",
            "positive": prompt,
            "negative": negativePrompt,
            "latent_image": ["2", 0]
          },
          "class_type": "KSampler"
        },
        "2": {
          "inputs": {
            "width": options.width,
            "height": options.height,
            "batch_size": options.fps * options.duration
          },
          "class_type": "EmptyLatentImage"
        },
        "3": {
          "inputs": {
            "samples": ["1", 0],
            "vae": "sdxl_vae.safetensors"
          },
          "class_type": "VAEDecode"
        },
        "4": {
          "inputs": {
            "images": ["3", 0],
            "frame_rate": options.fps,
            "loop_count": 0,
            "filename_prefix": "draft_video",
            "format": "mp4",
            "crf": 25,
            "save_metadata": true
          },
          "class_type": "SaveVideo"
        }
      }
    };
  }
  
  // Create a standard quality workflow (balanced)
  private createStandardWorkflow(prompt: string, negativePrompt: string, options: VideoGenerationOptions): any {
    // Similar to draft but with more steps and better settings
    return {
      "prompt": {
        "1": {
          "inputs": {
            "seed": Math.floor(Math.random() * 1000000),
            "steps": 20,
            "cfg": 7,
            "sampler_name": "dpmpp_2m",
            "scheduler": "karras",
            "denoise": 1,
            "model": "sd_xl_base_1.0.safetensors",
            "positive": prompt,
            "negative": negativePrompt,
            "latent_image": ["2", 0]
          },
          "class_type": "KSampler"
        },
        "2": {
          "inputs": {
            "width": options.width,
            "height": options.height,
            "batch_size": options.fps * options.duration
          },
          "class_type": "EmptyLatentImage"
        },
        "3": {
          "inputs": {
            "samples": ["1", 0],
            "vae": "sdxl_vae.safetensors"
          },
          "class_type": "VAEDecode"
        },
        "4": {
          "inputs": {
            "images": ["3", 0],
            "frame_rate": options.fps,
            "loop_count": 0,
            "filename_prefix": "standard_video",
            "format": "mp4",
            "crf": 18,
            "save_metadata": true
          },
          "class_type": "SaveVideo"
        }
      }
    };
  }
  
  // Create a high quality workflow (slower)
  private createHighQualityWorkflow(prompt: string, negativePrompt: string, options: VideoGenerationOptions): any {
    // This would be a more complex workflow with upscaling, etc.
    // For brevity, we're using a simplified version
    return {
      "prompt": {
        "1": {
          "inputs": {
            "seed": Math.floor(Math.random() * 1000000),
            "steps": options.quality === VideoQuality.HIGH ? 30 : 50,
            "cfg": 8,
            "sampler_name": "dpmpp_2m_sde",
            "scheduler": "karras",
            "denoise": 1,
            "model": "sd_xl_base_1.0.safetensors",
            "positive": prompt,
            "negative": negativePrompt,
            "latent_image": ["2", 0]
          },
          "class_type": "KSampler"
        },
        "2": {
          "inputs": {
            "width": options.width,
            "height": options.height,
            "batch_size": options.fps * options.duration
          },
          "class_type": "EmptyLatentImage"
        },
        "3": {
          "inputs": {
            "samples": ["1", 0],
            "vae": "sdxl_vae.safetensors"
          },
          "class_type": "VAEDecode"
        },
        "4": {
          "inputs": {
            "images": ["3", 0],
            "frame_rate": options.fps,
            "loop_count": 0,
            "filename_prefix": "high_quality_video",
            "format": "mp4",
            "crf": options.quality === VideoQuality.HIGH ? 15 : 10,
            "save_metadata": true
          },
          "class_type": "SaveVideo"
        }
      }
    };
  }

  // Generate a video from a prompt
  public async generateVideo(
    prompt: string,
    options?: Partial<VideoGenerationOptions>,
    progressCallback?: (progress: GenerationProgress) => void
  ): Promise<GenerationResult> {
    this.resetCancel();
    this.progressCallback = progressCallback;
    
    const mergedOptions = { ...this.options, ...(options || {}) };
    const totalSteps = 4; // script, audio, frames, compositing
    let currentStep = 0;
    
    try {
      // Step 1: Generate script
      this.updateProgress('generating_script', 'Generating video script...', 0, currentStep, totalSteps);
      const script = await this.generateScript(prompt);
      currentStep++;
      
      if (this.isCancelled) {
        throw new Error('Video generation cancelled');
      }
      
      // Step 2: Generate audio if TTS is enabled
      let audioBlob: Blob | null = null;
      if (mergedOptions.useTts) {
        this.updateProgress('generating_audio', 'Generating audio narration...', 25, currentStep, totalSteps);
        
        try {
          // Get TTS service from settings
          const ttsService = getTtsService();
          
          // Generate audio for the script
          const audioBlobs = await ttsService.synthesizeLongText(
            script,
            { voice: mergedOptions.ttsVoice },
            (progress) => {
              this.updateProgress(
                'generating_audio',
                `Generating audio narration... ${Math.round(progress * 100)}%`,
                25 + progress * 15,
                currentStep,
                totalSteps
              );
            }
          );
          
          // Combine audio blobs
          audioBlob = await ttsService.combineAudioBlobs(audioBlobs);
        } catch (error) {
          console.error('TTS generation error:', error);
          // Continue without audio if TTS fails
        }
      }
      
      currentStep++;
      
      if (this.isCancelled) {
        throw new Error('Video generation cancelled');
      }
      
      // Step 3: Generate video frames
      this.updateProgress('generating_frames', 'Generating video frames...', 40, currentStep, totalSteps);
      
      // Create workflow based on quality settings
      const workflow = this.createVideoWorkflow(prompt, undefined, mergedOptions);
      
      // Submit workflow to ComfyUI
      const response = await this.api.submitPrompt(workflow);
      const promptId = response.prompt_id;
      
      // Poll for completion (in a real implementation, this would use websockets)
      // This is a simplified polling approach
      let isComplete = false;
      while (!isComplete && !this.isCancelled) {
        // Wait a bit before checking again
        await new Promise(resolve => setTimeout(resolve, 1000));
        
        try {
          // Check history to see if our prompt is complete
          const history = await this.api.getHistoryItem(promptId);
          
          if (history && history.outputs) {
            isComplete = true;
            this.updateProgress('generating_frames', 'Video frames generated successfully!', 80, currentStep, totalSteps);
          }
        } catch (error) {
          console.error('Error checking generation status:', error);
        }
      }
      
      currentStep++;
      
      if (this.isCancelled) {
        throw new Error('Video generation cancelled');
      }
      
      // Step 4: Compositing (in a real implementation, this would combine the video and audio)
      this.updateProgress('compositing', 'Compositing final video...', 90, currentStep, totalSteps);
      
      // Simulate compositing delay
      await new Promise(resolve => setTimeout(resolve, 1000));
      
      currentStep++;
      
      // Complete!
      this.updateProgress('complete', 'Video generation complete!', 100, currentStep, totalSteps);
      
      // Return result
      return {
        videoUrl: `/view?filename=high_quality_video.mp4&type=output&subfolder=`,
        audioUrl: audioBlob ? URL.createObjectURL(audioBlob) : undefined,
        script,
        promptId
      };
    } catch (error) {
      console.error('Video generation error:', error);
      
      this.updateProgress(
        'error',
        'Video generation failed',
        0,
        currentStep,
        totalSteps,
        error instanceof Error ? error.message : 'Unknown error'
      );
      
      return {
        error: error instanceof Error ? error.message : 'Unknown error occurred during video generation'
      };
    }
  }
}

// Create a singleton instance
let videoGenerationServiceInstance: VideoGenerationService | null = null;

export const getVideoGenerationService = (api: ApiService, options?: Partial<VideoGenerationOptions>): VideoGenerationService => {
  if (!videoGenerationServiceInstance) {
    videoGenerationServiceInstance = new VideoGenerationService(api, options);
  } else if (options) {
    videoGenerationServiceInstance.setOptions(options);
  }
  
  return videoGenerationServiceInstance;
};

export const resetVideoGenerationService = (): void => {
  videoGenerationServiceInstance = null;
}; 